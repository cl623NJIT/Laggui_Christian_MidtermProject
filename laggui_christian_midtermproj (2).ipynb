{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06cb97ec-8ecb-46e3-be68-e29cd0980e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: apriori_python in c:\\users\\clagg\\anaconda3\\lib\\site-packages (1.0.4)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which store would you like to explore?\n",
      "1. Amazon \n",
      "2. BestBuy \n",
      "3. Kmart \n",
      "4. Nike \n",
      "5. Staples \n",
      "\n",
      " 1\n",
      "\n",
      "min_support %:\t 50\n",
      "\n",
      "min_confidence %:\t 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frequent itemsets with size 3\n",
      "Java: The Complete Reference -> Java For Dummies: \n",
      " Support: 50.0 | Confidence: 100.0\n",
      "Java For Dummies -> Java: The Complete Reference: \n",
      " Support: 50.0 | Confidence: 76.92307692307693\n",
      "Rule 1: Java: The Complete Reference -> Java For Dummies: 100.0\n",
      "\n",
      "Rule 2: Java For Dummies -> Java: The Complete Reference: 76.92307692307693\n",
      "\n",
      "Execution time: 0.021968 seconds\n",
      "\n",
      "\n",
      "Apriori:\n",
      "\n",
      "Rule 1: [{'Java For Dummies'}, {'Java: The Complete Reference'}, 0.7692307692307693]\n",
      "\n",
      "Rule 2: [{'Java: The Complete Reference'}, {'Java For Dummies'}, 1.0]\n",
      "\n",
      "Execution time: 0.000000 seconds\n"
     ]
    }
   ],
   "source": [
    "!pip install apriori_python\n",
    "from apriori_python.apriori import apriori\n",
    "import time\n",
    "import pandas as pd\n",
    "from itertools import combinations, chain\n",
    "from collections import defaultdict\n",
    "\n",
    "# Store DataSet Directories\n",
    "def openStore(value):\n",
    "  value = int(value)\n",
    "  match value:\n",
    "    case 1:\n",
    "      return r'./Downloads/Data/Amazon'\n",
    "    case 2:\n",
    "      return r'./Downloads/Data/BestBuy/'\n",
    "    case 3:\n",
    "      return r'./Downloads/Data/Kmart/'\n",
    "    case 4:\n",
    "      return r'./Downloads/Data/Nike/'\n",
    "    case 5:\n",
    "      return r'./Downloads/Data/Staples/'\n",
    "\n",
    "#function to count itemset frequency\n",
    "def count_items(itemset, transactions):\n",
    "  count = 0\n",
    "  #iterate through the transactions to check if item is frequent\n",
    "  for i in range(len(transactions)):\n",
    "    #check if the item is in the transaction. increment count if true\n",
    "    #if set(itemset).issubset(transactions.loc[i, 'Transaction']):\n",
    "    if all(item in transactions.loc[i, 'Transaction'] for item in itemset):\n",
    "      count += 1\n",
    "  return count\n",
    "\n",
    "#function to get unique items in transaction dataframe\n",
    "def CreateItemset(transactions):\n",
    "  allItems = transactions['Transaction'].str.split(', ').explode().apply(lambda x: x.strip()).unique()\n",
    "  return allItems\n",
    "\n",
    "\n",
    "def aprioriItemset(transactions, itemset, min_support, k = 1, output = {}, ):\n",
    "\n",
    "  #k_output is the temporary dictionary that holds information for this iteration\n",
    "  #   size:\n",
    "  #   frequent_items: {}\n",
    "  #   singleton_items: []\n",
    "\n",
    "  k_output = {}\n",
    "  k_output['size'] = k\n",
    "\n",
    "  #temporary structures to hold values\n",
    "  frequent_itemsets = {}\n",
    "  pruned_itemsets = []\n",
    "  singleton_items = []\n",
    "\n",
    "  #iterate through each item- check if they are frequent\n",
    "  for item in itemset:\n",
    "    #after each item, check if the item is > min_support. Append to output if true\n",
    "    frequentItem, support = checkSupport(transactions, item, min_support)\n",
    "    if frequentItem:\n",
    "      frequent_itemsets[f'{item}'] = support\n",
    "      singleton_items = addSingleton(item, singleton_items)\n",
    "    else:\n",
    "      pruned_itemsets.append(item)\n",
    "\n",
    "  #exit the function if there are no more combinations available.\n",
    "  if len(frequent_itemsets.keys()) == 0:\n",
    "    print(f'No frequent itemsets with size {k}')\n",
    "    output['max_size'] = k-1\n",
    "    return output\n",
    "  #if we found frequent items in this iteration, try to iterate once more k++\n",
    "  else:\n",
    "    k_output['frequent_itemsets'] = frequent_itemsets\n",
    "    #k_output['singleton_items'] = singleton_items\n",
    "    output[f'{k}'] = k_output\n",
    "    k += 1\n",
    "\n",
    "  #recursively call the function\n",
    "  aprioriItemset(transactions, getCombinations(singleton_items, k), min_support, k)\n",
    "  return output\n",
    "\n",
    "#function to calcualte the support of an itemset\n",
    "def checkSupport(transactions, itemset, min_support):\n",
    "  support = count_items(itemset, transactions) / len(transactions) * 100\n",
    "  if support >= min_support:\n",
    "    return True, support\n",
    "  else:\n",
    "    return False, support\n",
    "\n",
    "def getCombinations(itemset, k):\n",
    "  return list(combinations(itemset, k))\n",
    "\n",
    "def addSingleton(item, singleton_list):\n",
    "  singletonSet = set(singleton_list)\n",
    "  # If the item is a tuple, iterate over its elements\n",
    "  if isinstance(item, tuple):\n",
    "      for sub_item in item:\n",
    "          # Add the sub_item to the list if it's not already in the set\n",
    "          if sub_item not in singleton_list:\n",
    "              singleton_list.append(sub_item)\n",
    "              singletonSet.add(sub_item)  # Keep the set updated\n",
    "  # If the item is a single string, check if it's unique\n",
    "  elif isinstance(item, str):\n",
    "      if item not in singleton_list:\n",
    "          singleton_list.append(item)\n",
    "          singletonSet.add(item)  # Keep the set updated\n",
    "  return singleton_list\n",
    "\n",
    "def checkConfidence(input, min_confidence):\n",
    "  k = input['max_size']\n",
    "  output = {}\n",
    "  while k > 1:\n",
    "    itemsets = list(input[f'{k}']['frequent_itemsets'].keys())\n",
    "    for i in itemsets:\n",
    "      itemset = eval(i)\n",
    "      for j in list(itemset):\n",
    "        confidence = input[f'{k}']['frequent_itemsets'][i] / input['1']['frequent_itemsets'][j] * 100\n",
    "        consequent = [i for i in itemset if i != j]\n",
    "        if confidence >= float(min_confidence):\n",
    "          output[f'{j} -> {\", \".join(consequent)}'] = confidence\n",
    "          if(k == input['max_size']):\n",
    "            print(f'{j} -> {\", \".join(consequent)}: \\n Support: {input[f\"{k}\"][\"frequent_itemsets\"][i]} | Confidence: {confidence}')\n",
    "    k -= 1\n",
    "  return output\n",
    "\n",
    "\n",
    "# Ask for input. Select the store\n",
    "storeSelected = input(\"Which store would you like to explore?\\n1. Amazon \\n2. BestBuy \\n3. Kmart \\n4. Nike \\n5. Staples \\n\\n\")\n",
    "\n",
    "path = openStore(storeSelected)\n",
    "\n",
    "supportNum = input(\"\\nmin_support %:\\t\")\n",
    "confidenceNum = input(\"\\nmin_confidence %:\\t\")\n",
    "# Load and clean the datasets\n",
    "with open(path + '/Transactions.csv', 'r') as transaction_file:\n",
    "  transactions = pd.read_csv(transaction_file)\n",
    "  try:\n",
    "    with open(path + '/Items.csv', 'r') as item_file:\n",
    "      itemset = pd.read_csv(item_file)\n",
    "  except FileNotFoundError:\n",
    "    print(f\"File not found: {item_file}\")\n",
    "  else:\n",
    "    CreateItemset(transactions)\n",
    "  finally:\n",
    "    #print(transactions)\n",
    "    start_time = time.time()\n",
    "    frequent_itemsets = aprioriItemset(transactions, itemset['Item Name'], float(supportNum))\n",
    "    confidence = checkConfidence(frequent_itemsets, confidenceNum)\n",
    "    for i, (key,value) in enumerate(confidence.items()):\n",
    "      print(f'Rule {i+1}: {key}: {value}\\n')\n",
    "      \n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "    \n",
    "    transactions['Transaction'] = transactions['Transaction'].apply(lambda x: x.split(', '))\n",
    "    df_transactions = transactions.drop('Transaction ID', axis=1)\n",
    "    #print(df_transactions)\n",
    "    # Convert the DataFrame into a list of transactions (rows to lists)\n",
    "    transactions = df_transactions.apply(lambda x: x.dropna().tolist(), axis=1).tolist()\n",
    "    #print(transactions)\n",
    "    flattened_transactions = [transaction[0] for transaction in transactions]\n",
    "\n",
    "    astart_time = time.time()\n",
    "    freqItemSet, rules = apriori(flattened_transactions, float(supportNum)/100, float(confidenceNum)/100)\n",
    "\n",
    "    print(\"\\n\\nApriori:\\n\")\n",
    "    for i, rule in enumerate(rules):\n",
    "      print(f\"Rule {i + 1}: {rule}\\n\")\n",
    "\n",
    "    aend_time = time.time()\n",
    "    execution_time = aend_time - astart_time\n",
    "    print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e6ecf3-4327-4840-926c-9b266a84f594",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
